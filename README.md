# Spotify ETL Pipeline to BigQuery

Pipeline completo de extracciÃ³n, transformaciÃ³n y carga (ETL) de datos desde Spotify API hacia BigQuery, con visualizaciÃ³n en Streamlit y documentaciÃ³n completa.

## ğŸ¯ CaracterÃ­sticas

- **ExtracciÃ³n de datos** desde Spotify API (perfil, playlists, tracks, artistas, historial)
- **TransformaciÃ³n y validaciÃ³n** de datos con Pydantic
- **Carga a BigQuery** con estrategia upsert/incremental
- **Dashboard interactivo** con Streamlit
- **DocumentaciÃ³n completa** con MkDocs
- **OptimizaciÃ³n de costos** para mantenerse en la capa gratuita de BigQuery

## ğŸ“‹ Requisitos

- Python 3.11+
- Cuenta de Spotify Developer (Client ID y Client Secret)
- Proyecto de Google Cloud Platform con BigQuery habilitado
- Credenciales de servicio de GCP (JSON)

## ğŸš€ InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone <repository-url>
cd Spotify-api
```

2. Crear entorno virtual:
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. Instalar dependencias:
```bash
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Para desarrollo
```

4. Configurar variables de entorno:
```bash
cp .env.example .env
# Editar .env con tus credenciales
```

5. Configurar credenciales de GCP:
```bash
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"
```

## ğŸ“– Uso

### Setup inicial de BigQuery

```bash
python scripts/setup_bigquery.py
```

### Ejecutar pipeline ETL

```bash
python scripts/run_etl.py
```

### Ejecutar dashboard Streamlit

```bash
streamlit run streamlit_app/main.py
```

### Monitorear costos

```bash
python scripts/monitor_costs.py
```

## ğŸ“ Estructura del Proyecto

```
Spotify-api/
â”œâ”€â”€ config/              # ConfiguraciÃ³n y schemas
â”œâ”€â”€ src/                 # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ spotify/        # Cliente y extractores de Spotify
â”‚   â”œâ”€â”€ bigquery/       # Cliente y loader de BigQuery
â”‚   â””â”€â”€ utils/          # Utilidades (logging, validadores)
â”œâ”€â”€ pipelines/          # Pipelines ETL
â”œâ”€â”€ streamlit_app/      # AplicaciÃ³n Streamlit
â”œâ”€â”€ tests/              # Tests unitarios
â”œâ”€â”€ scripts/            # Scripts ejecutables
â””â”€â”€ docs/               # DocumentaciÃ³n MkDocs
```

## ğŸ”§ ConfiguraciÃ³n

Ver `.env.example` para todas las variables de entorno necesarias.

### LÃ­mites de extracciÃ³n (para optimizar costos)

- MÃ¡ximo 20 playlists
- MÃ¡ximo 100 tracks por playlist
- Ãšltimas 50 reproducciones recientes
- Top 20 tracks/artists por perÃ­odo

## ğŸ“š DocumentaciÃ³n

Para generar y ver la documentaciÃ³n:

```bash
mkdocs serve
```

Luego abrir http://localhost:8000

## ğŸ§ª Testing

```bash
pytest
```

Con cobertura:

```bash
pytest --cov=src --cov-report=html
```

## ğŸ“Š OptimizaciÃ³n de Costos

Este proyecto estÃ¡ diseÃ±ado para mantenerse dentro de la capa gratuita de BigQuery:
- 10 GB de almacenamiento/mes (gratis)
- 1 TB de consultas/mes (gratis)

Ver `docs/deployment.md` para mÃ¡s detalles sobre monitoreo de costos.

## ğŸ“ Licencia

MIT

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request.

